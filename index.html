<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>S. Mahdi H. Miangoleh</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <style>
body {
    display: flex;
    justify-content: center;
    align-items: center;
    min-height: 100vh;
    margin: 0;
    font-family: 'Segoe UI', sans-serif;
}

.content {
    width: 90%;
    max-width: 800px;
    margin-top: 40px;
    margin-bottom: 40px;
}

.profile {
    display: flex;
    flex-direction: row;
    justify-content: space-between;
    align-items: center;
}

.profile-text {
    flex: 2;
    margin-right: 15px;
    margin-left: 15px;
}

.profile-image {
    flex: 1.1;
    width: 40%;
    height: 40%;
}

.profile-pic {
    width: 100%;
    height: 100%;
    border-radius: 50%;
}

.profile-links {
    text-align: center;
    margin-top: 10px;
}

.profile-links a {
            margin-right: 10px; /* Adjust the spacing as needed */
        }

.publication-item {
    display: flex;
    flex-direction: row;
    justify-content: space-between;
    margin-bottom: 20px;
    align-items: center;
}

.image-container {
    width: 25%;
    margin-right: 20px;
}

.publication-image {
    width: 100%;
    border-radius: 30%;
}

.publication-content {
    width: 100%;
    text-align: left;
}


/* Reducing font size for headings */
h1 {
    font-size: 32px; /* Adjust the size as needed */
    font-weight: 600
}

h2 {
    font-size: 20px;
}

/* Reducing font size for paragraphs */
p {
    font-size: 14px;
}

/* Style for .type2 */
strong.type2 {
    font-weight: 600
}

strong.pubtitle {
    color: navy;
}

a {
    font-size: 14px;
    color: #0000EE; /* Change this to the color you prefer */
}

a:visited {
    color: #0000EE; /* Same color as the unvisited link */
}
/* This will style the links when hovered over */
a:hover {
    color: orange; /* Hover link color */
}

a:visited:hover {
    color: orange; /* Hover link color */
}

/* Override the visited link color to be the same as unvisited */


@media (max-width: 768px) {
    .profile {
        flex-direction: column;
        align-items: center;
    }

    .profile-image {
    width: 80%;
    height: 80%;
    order: 1
    }

    .profile-text {
        order: 2; /* Move text below the image */
    }
}

</style>

</head>


<body>
    <div class="content">

    <div class="profile">
        <div class="profile-text">
            <h1 align="center">S. Mahdi H. Miangoleh</h1>
            <p>I am a <em>Computing Science</em> PhD student at Simon Fraser University (SFU). I do research at <strong>Computational Photography Lab</strong> under the supervision of Prof. <a href="http://yaksoy.github.io/">Yağız Aksoy</a>.</p>
            <p>I got my Master's degree in Computing Science at SFU in <strong>Summer 2022</strong>. My MSc Thesis is on <a href="http://yaksoy.github.io/bmd-msc/"><em>Boosting Monocular Depth Estimation to High Resolution</em></a>.</p>
            <p>Before joining SFU I got my bachelor's degree in Electrical Engineering-Digital Systems at Sharif University of Technology.</p>
            <br>
            <p class="profile-links">
                <a href="mailto:mahdi_miangoleh@sfu.ca", title="Email"><i class="fas fa-envelope fa-2x"></i></a>
                <a href="https://github.com/miangoleh/", title="Github"><i class="fab fa-github fa-2x"></i></a>
                <a href="https://twitter.com/mahdi_miangoleh", title="Twitter"><i class="fab fa-twitter fa-2x"></i></a>
                <a href="https://scholar.google.ca/citations?user=mqJpOqkAAAAJ&hl=en", title="Google scholar"><i class="fas fa-graduation-cap fa-2x"></i></a>
                <a href="https://linkedin.com/in/miangoleh", title="LinkedIn"><i class="fab fa-linkedin fa-2x"></i></a>
            </p>
            
        </div>
        <div class="profile-image">
            <img src="mypic2.JPG" alt="Mahdi Miangoleh" class="profile-pic">
        </div>   
    </div>

    <h2>News</h2>
    <p>I started an Internship at <strong>Bosch AI</strong> under <a href="https://yuliangguo.github.io/">Yuliang Guo</a>! (May 2023)</p>
    <p>I graduated with a Master's degree in Computing Science from Simon Fraser University (<a href="http://yaksoy.github.io/bmd-msc/">Thesis</a>)! I will be continuing my studies toward a PhD degree under supervision of Prof. <a href="http://yaksoy.github.io/">Yağız Aksoy</a>. (August 2022)</p>
    <p>I started an Internship at <strong>Adobe Research</strong> working with <a href="http://zoyathinks.com/">Zoya Bylinskii</a>! (August 2021)</p>


    <h2>Research</h2>

    <p>
    My research focuses on computational photography, 3D computer vision, learning-based approaches for vision and graphics, and realistic image editing. I also have experience in embedded systems and desktop front-end application development.
    </p>
    
    <br>
    <br>

    <div class="publication-item">
        <div class="image-container">
            <a href="https://yaksoy.github.io/sidepth/">
                <img src="https://yaksoy.github.io/images/research/sidepth.jpg" alt="SIDepth" class="publication-image" />
            </a>
        </div>
        <div class="publication-content">
            <p>
            <strong class="pubtitle">Scale-Invariant Monocular Depth Estimation via SSI Depth</strong>
            <br>
            <strong>S. Mahdi H. Miangoleh</strong>, Mahesh Reddy, Yağız Aksoy
            <br>
            Proc <strong class="type2">SIGGRAPH 2024</strong>
            <br>
                <a href="https://yaksoy.github.io/sidepth/">[Project page]</a>
                <a href="https://yaksoy.github.io/papers/SIG24-SI-Depth.pdf">[PDF]</a>
                <a href="https://github.com/compphoto/sidepth">[Github]</a>
            </p>
            <p>
            We present a novel approach that leverages SSI depth inputs to enhance SI depth estimation, streamlining the network's role and facilitating in-the-wild generalization for SI depth estimation while only using a synthetic dataset for training.
            </p>
        </div>
    </div>

    <div class="publication-item">
        <div class="image-container">
            <a href="https://yaksoy.github.io/intrinsicCompositing/">
                <img src="https://yaksoy.github.io/images/research/intrinsicCompositing.jpg" alt="IntrinsicCompositing" class="publication-image" />
            </a>
        </div>
        <div class="publication-content">
            <p>
            <strong class="pubtitle">Intrinsic Harmonization for Illumination-Aware Compositing</strong>
            <br>
            Chris Careaga, <strong>S. Mahdi H. Miangoleh</strong>, Yağız Aksoy
            <br>
            Proc <strong class="type2">SIGGRAPH Asia 2023</strong>
            <br>
            <a href="https://yaksoy.github.io/intrinsicCompositing/">[Project page]</a>
            <a href="https://yaksoy.github.io/papers/SigAsia23-IntrinsicCompositing.pdf">[PDF]</a>
            <a href="https://github.com/compphoto/IntrinsicCompositing">[Github]</a>
            </p>
            <p>
            We introduce a self-supervised illumination harmonization approach formulated in the intrinsic image domain. First, we estimate a simple global lighting model from mid-level vision representations to generate a rough shading for the foreground region. A network then refines this inferred shading to generate a harmonious re-shading that aligns with the background scene.
            </p>
        </div>
    </div>

    <div class="publication-item">
        <div class="image-container">
            <a href="http://yaksoy.github.io/realisticEditing/">
                <img src="http://yaksoy.github.io/images/research/realisticEditing.jpg" alt="RealisticEditing" class="publication-image" />
            </a>
        </div>
        <div class="publication-content">
            <p>
            <strong class="pubtitle">Realistic Saliency Guided Image Enhancement</strong>
            <br>
            <strong>S. Mahdi H. Miangoleh</strong>, Zoya Bylinskii, Eric Kee, Eli Shechtman, Yağız Aksoy
            <br>
            Proc <strong class="type2">CVPR 2023</strong>
            <br>
                <a href="http://yaksoy.github.io/realisticEditing/">[Project page]</a>
                <a href="http://yaksoy.github.io/papers/CVPR23-RealisticEditing.pdf">[PDF]</a>
                <a href="https://github.com/compphoto/RealisticImageEnhancement">[Github]</a>
            </p>
            <p>
                We train and expliot a problem specific realism network to train a saliency-guided image enhancement network which allows maintaining high realism across varying image types while attenuating distractors and amplifying objects of interest. Our proposed approach offers a viable solution for automating image enhancement and photo cleanup operations.
            </p>
        </div>
    </div>

    <div class="publication-item">
        <div class="image-container">
            <a href="http://yaksoy.github.io/highresdepth/">
                <img src="http://yaksoy.github.io/images/research/highresdepth.jpg" alt="highresdepth" class="publication-image" />
            </a>
        </div>
        <div class="publication-content">
            <p>
            <strong class="pubtitle">Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging</strong>
            <br>
            <strong>S. Mahdi H. Miangoleh*</strong>, Sebastian Dille*, Long Mai, Sylvain Paris, Yağız Aksoy
            <br>
            Proc <strong class="type2">CVPR 2021</strong>
            <br>
                <a href="http://yaksoy.github.io/highresdepth/">[Project page]</a>
                <a href="http://yaksoy.github.io/papers/CVPR21-HighResDepth.pdf">[PDF]</a>
                <a href="https://github.com/compphoto/BoostingMonocularDepth">[Github]</a>
            </p>
            <p>
            We demonstrate that there is a trade-off between a consistent scene structure and the high-frequency details, and merge low- and high-resolution estimations to take advantage of this duality using a simple depth merging network and generate multi-megapixel depth maps with a high level of detail using a pre-trained model.
            </p>
        </div>
    </div>

    <div class="publication-item">
        <div class="image-container">
            <a href="http://yaksoy.github.io/interactiveDepth/">
                <img src="http://yaksoy.github.io/images/research/interactiveDepth.jpg" alt="interactiveeditdepth" class="publication-image" />
            </a>
        </div>
        <div class="publication-content">
            <p>
            <strong class="pubtitle">Interactive Editing of Monocular Depth</strong>
            <br>
            Obumneme Stanley Dukor, <strong>S. Mahdi H. Miangoleh</strong>, Mahesh Kumar Krishna Reddy, Long Mai, Yağız Aksoy
            <br>
            Proc <strong class="type2">SIGGRAPH POSTER 2022</strong>
            <br>
                <a href="http://yaksoy.github.io/interactiveDepth/">[Project page]</a>
                <a href="http://yaksoy.github.io/papers/SIG22a-interactiveDepth.pdf">[PDF]</a>
                <a href="https://depth-app.netlify.app/editor">[Web Application]</a>
            </p>
            <p>
            In this work, we present a lightweight, web-based interactive depth editing and visualization tool that adapts low-level conventional image editing operations for geometric manipulation to enable artistic control in the 3D photography workflow.
            </p>
        </div>
    </div>

    <h2>Theses</h2>
    <div class="publication-item">
        <div class="image-container">
            <a href="http://yaksoy.github.io/bmd-msc/">
                <img src="http://yaksoy.github.io/images/research/mahdimsc.jpg" alt="bmdthesis" class="publication-image" />
            </a>
        </div>
        <div class="publication-content">
            <p>
            <strong class="pubtitle">Boosting Monocular Depth Estimation to High Resolution</strong>
            <br>
            MSc Thesis
            <br>
            <strong>Seyed Mahdi Hosseini Miangoleh</strong>
            <br>
                <a href="http://yaksoy.github.io/bmd-msc/">[Project page]</a>
                <a href="https://sfu.ca/~smh31/masterthesis">[PDF]</a>
            </p>
            <p>
                We demonstrate that there is a trade-off between a consistent scene structure and the high-frequency details, and merge low- and high-resolution estimations to take advantage of this duality using a simple depth merging network and generate multi-megapixel depth maps with a high level of detail using a pre-trained model.
            </p>
        </div>
    </div>
</div>
</body>
</html>
